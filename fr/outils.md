# CLEF 2024 SimpleText: Tools

[Accueil](./) | [Appel à communications](./CFD.md) | [Dates importantes](./dates.md) | [Tâches](./taches.md)  | [Outils](./outils.md) | 
[Programme](./programme.md) | [Publications](./publications.md) | [Organisateurs](./organisateurs.md) | [Contact](./contact.md) | [CLEF-2023](https://simpletext-project.com/2023/clef/)

---

## Littérature et outils pertinents
### Tâche 1 : Outils de résumé automatique
* Les classificateurs populaires sont Anserini/Pyserini ou les classificateurs neuronaux entraînés sur HuggingFace.
* La piste met une API de recherche élastique à la disposition des participants inscrits.

### Tâche 2 : Outils de gestion terminologique
* **IDF** : Robertson, S. (2004), « Understanding inverse document frequency : on theoretical arguments for IDF », Journal of Documentation, Vol. 60 No. 5, pp. 503-520. [https://doi.org/10.1108/00220410410560582](https://doi.org/10.1108/00220410410560582)

### Tâche 3 : Outils de simplification de texte
**JURASSIC** : AI21 Studio donne accès à la suite de modèles linguistiques Jurassic-1. Jurassic-1 Jumbo est le plus grand modèle disponible publiquement sans liste d'attente. Le terrain de jeu du studio AI21 fournit des promts prêts à l'emploi pour la simplification des textes (voir De-Jargonizer) [https://www.ai21.com/studio](https://www.ai21.com/studio)
**GPT-2** est un modèle de langage non supervisé à grande échelle qui effectue la traduction automatique, la réponse aux questions et le résumé sans formation spécifique à la tâche [https://github.com/openai/gpt-2](https://github.com/openai/gpt-2)
**Le modèle transformateur T5 multilingue (mT5)** peut être affiné pour la simplification du texte, par exemple en utilisant la [bibliothèque SimpleT5] (https://github.com/Shivanandroy/simpleT5/). [https://github.com/google-research/multilingual-t5](https://github.com/google-research/multilingual-t5)
